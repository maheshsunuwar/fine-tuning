{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert'>\n",
    "\n",
    "### Fine Tuning LLM - GPT2\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class='alert alert-success'>\n",
    "Lets Start.\n",
    "\n",
    "We will follow these steps:\n",
    "1. Choose a pre-trained model and a dataset\n",
    "2. Load the data\n",
    "3. Tokenizer\n",
    "4. Initialize our base model\n",
    "5. Evaluate the method\n",
    "6. Fine tune using the Trainer method\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert'>\n",
    "\n",
    "#### 1. Choose a pre-trained model and a dataset\n",
    "\n",
    "</div>\n",
    "\n",
    "Lets use *`gpt2`* model and a *`twitter dataset`*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert'>\n",
    "\n",
    "#### 2. Load the dataset\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'text', 'label', 'label_text'],\n",
       "        num_rows: 27481\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'text', 'label', 'label_text'],\n",
       "        num_rows: 3534\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "twitter_dataset = load_dataset(\"mteb/tweet_sentiment_extraction\")\n",
    "twitter_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cb774db0d1</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549e992a42</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>088c60f138</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9642c003ef</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358bd9e861</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         text  label  \\\n",
       "id                                                                     \n",
       "cb774db0d1                I`d have responded, if I were going      1   \n",
       "549e992a42      Sooo SAD I will miss you here in San Diego!!!      0   \n",
       "088c60f138                          my boss is bullying me...      0   \n",
       "9642c003ef                     what interview! leave me alone      0   \n",
       "358bd9e861   Sons of ****, why couldn`t they put them on t...      0   \n",
       "\n",
       "           label_text  \n",
       "id                     \n",
       "cb774db0d1    neutral  \n",
       "549e992a42   negative  \n",
       "088c60f138   negative  \n",
       "9642c003ef   negative  \n",
       "358bd9e861   negative  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pprint\n",
    "\n",
    "training_dataset = pd.DataFrame(twitter_dataset['train'])\n",
    "testing_dataset = pd.DataFrame(twitter_dataset['test'])\n",
    "\n",
    "training_dataset.set_index('id', inplace=True)\n",
    "testing_dataset.set_index('id', inplace=True)\n",
    "\n",
    "training_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((27481, 3),\n",
       " (3534, 3),\n",
       " array(['neutral', 'negative', 'positive'], dtype=object))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset.shape, testing_dataset.shape, training_dataset['label_text'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the labels are `neutral`, `negative`, and `positive`.\n",
    "\n",
    "So our goal is to classify the sentiment of the `text` into those `labels`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11118, 7781, 8582)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if the labels have balanced data\n",
    "total_neutral = len(training_dataset[training_dataset['label'] == 1])\n",
    "total_negative = len(training_dataset[training_dataset['label'] == 0])\n",
    "total_positive = len(training_dataset[training_dataset['label'] == 2])\n",
    "\n",
    "total_neutral, total_negative, total_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 3 artists>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.barh(['neutral', 'negative', 'positive'], [total_neutral, total_negative, total_positive])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like neutral has more data. but its not a lot, so it is acceptable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert'>\n",
    "\n",
    "#### 3. Load the tokenizer\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('google-bert/bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As LLMs work with tokens, we need to tokenize our entire dataset using the tokenizer.\n",
    "\n",
    "We can use map method to apply the preprocessing function over the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "# d = load_dataset(\"mteb/tweet_sentiment_extraction\")\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "# t.pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def tokenize_function(observation):\n",
    "    return tokenizer(observation['text'], padding='max_length', truncation=True)\n",
    "\n",
    "tokenized_dataset = twitter_dataset.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['id', 'text', 'label', 'label_text', 'input_ids', 'attention_mask'],\n",
       "     num_rows: 27481\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['id', 'text', 'label', 'label_text', 'input_ids', 'attention_mask'],\n",
       "     num_rows: 3534\n",
       " }))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset['train'], tokenized_dataset['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert'>\n",
    "\n",
    "#### 4. Initialize our base model\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# model = AutoModelForMaskedLM.from_pretrained('google-bert/bert-base-uncased', num_labels=3)\n",
    "\n",
    "from transformers import GPT2ForSequenceClassification\n",
    "\n",
    "model = GPT2ForSequenceClassification.from_pretrained(\"gpt2\", num_labels=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert'>\n",
    "\n",
    "#### 5. Evaluate\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "   logits, labels = eval_pred\n",
    "   predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "   return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert'>\n",
    "\n",
    "#### 6. Fine-tune the model\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20610' max='20610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20610/20610 3:52:48, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.883400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.723400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.725400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.719200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.657300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.681800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.663300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.655700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.669000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.679600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.659100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.675200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.677100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.593100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.594000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.580800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.590500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.567600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.599200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.546600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.622300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.598500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.587800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.589500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.583300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.611200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.559700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.533300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.504000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.503900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.482000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.541400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.442200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.547300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.465900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.479200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.479000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.487100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.429200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.498400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>0.516900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=20610, training_loss=0.5891319002820589, metrics={'train_runtime': 13970.0241, 'train_samples_per_second': 5.901, 'train_steps_per_second': 1.475, 'total_flos': 4.307986164901478e+16, 'train_loss': 0.5891319002820589, 'epoch': 2.9996725010006915})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "   output_dir=\"test_trainer\",\n",
    "   #evaluation_strategy=\"epoch\",\n",
    "   per_device_train_batch_size=1,  # Reduce batch size here\n",
    "   per_device_eval_batch_size=1,    # Optionally, reduce for evaluation as well\n",
    "   gradient_accumulation_steps=4\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "   model=model,\n",
    "   args=training_args,\n",
    "   train_dataset=tokenized_dataset['train'],\n",
    "   eval_dataset=tokenized_dataset['test'],\n",
    "   compute_metrics=compute_metrics,\n",
    "\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# model_state_dict = torch.load('test_trainer/checkpoint-20610/rng_state.pth', weights_only=True)\n",
    "\n",
    "# model.load_state_dict(model_state_dict)\n",
    "\n",
    "\n",
    "from transformers import GPT2ForSequenceClassification\n",
    "model = GPT2ForSequenceClassification.from_pretrained(\"test_trainer/checkpoint-20610\", use_safetensors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When loading a model saved with safetensors format, you need to point to the directory containing the model files, not directly to the model.safetensors file itself. The correct approach would be:\n",
    "\n",
    "```Python\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "# Incorrect (causing the error)\n",
    "model = AutoModel.from_pretrained('test_trainer/checkpoint-20610/model.safetensors')\n",
    "\n",
    "# Correct\n",
    "model = AutoModel.from_pretrained('test_trainer/checkpoint-20610', use_safetensors=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2ForSequenceClassification(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (score): Linear(in_features=768, out_features=3, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets evaluate the trained model now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "# configure training argument for the evaluation\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='evaluate_model',\n",
    "    per_device_eval_batch_size=1,\n",
    "    prediction_loss_only=False\n",
    ")\n",
    "\n",
    "# initialize evaluator\n",
    "evaluator = Trainer(\n",
    "    model=model,\n",
    "    args=training_args, # more like evaluating arguments\n",
    "    # tokenizer = tokenizer, # note we are using  tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "    # # eval_dataset=tokenized_dataset['test'],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3534' max='3534' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3534/3534 04:27]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_results = evaluator.evaluate(tokenized_dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.9359921216964722,\n",
       " 'eval_model_preparation_time': 0.0044,\n",
       " 'eval_runtime': 271.9477,\n",
       " 'eval_samples_per_second': 12.995,\n",
       " 'eval_steps_per_second': 12.995}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "default trainer doesn't give other metrics.\n",
    "\n",
    "We have to write a custom function that handles this.\n",
    "\n",
    "Lets do that now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3534' max='3534' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3534/3534 02:40]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "def custom_metrics(predictions):\n",
    "    pred, labels = predictions\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    precision = precision_score(y_true=labels, y_pred=pred, average='macro')\n",
    "    recall = recall_score(y_true=labels, y_pred=pred, average='macro')\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred, average='macro')\n",
    "    # average = macro, we should do this for multiclass classfication\n",
    "    # we can choose from micro, macro, and weighted options\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }\n",
    "\n",
    "## update the evaluator\n",
    "evaluator = Trainer(\n",
    "    model=model,\n",
    "    args=training_args, # more like evaluating arguments\n",
    "    compute_metrics=custom_metrics\n",
    ")\n",
    "\n",
    "eval_results = evaluator.evaluate(tokenized_dataset['test'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.9359921216964722,\n",
       " 'eval_model_preparation_time': 0.0036,\n",
       " 'eval_accuracy': 0.7874929258630448,\n",
       " 'eval_precision': 0.788823084619586,\n",
       " 'eval_recall': 0.7929297659125402,\n",
       " 'eval_f1': 0.7906929181372236,\n",
       " 'eval_runtime': 161.2544,\n",
       " 'eval_samples_per_second': 21.916,\n",
       " 'eval_steps_per_second': 21.916}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!!! \n",
    "\n",
    "We got accuracy of around 79%.\n",
    "\n",
    "![dancing](https://media1.tenor.com/m/RdYowW9KtNMAAAAC/dancing-happy-dance.gif)\n",
    "\n",
    "\n",
    "But We didnt check the base model's performance before. \n",
    "\n",
    "Lets check if the base models performance is less or greater than 79."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "base_model = GPT2ForSequenceClassification.from_pretrained(\"gpt2\", num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3534' max='3534' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3534/3534 02:42]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/loki/micromamba/envs/agentic/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.4421862363815308,\n",
       " 'eval_model_preparation_time': 0.0019,\n",
       " 'eval_accuracy': 0.30220713073005095,\n",
       " 'eval_precision': 0.2292054310600545,\n",
       " 'eval_recall': 0.33446553446553445,\n",
       " 'eval_f1': 0.2146026926803921,\n",
       " 'eval_runtime': 162.8452,\n",
       " 'eval_samples_per_second': 21.702,\n",
       " 'eval_steps_per_second': 21.702}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## update the evaluator\n",
    "base_evaluator = Trainer(\n",
    "    model=base_model,\n",
    "    args=training_args, # more like evaluating arguments\n",
    "    compute_metrics=custom_metrics\n",
    ")\n",
    "\n",
    "base_eval_results = base_evaluator.evaluate(tokenized_dataset['test'])\n",
    "\n",
    "base_eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Base Model</th>\n",
       "      <th>Fine-tuned Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eval_loss</th>\n",
       "      <td>1.442186</td>\n",
       "      <td>0.935992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_model_preparation_time</th>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.003600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_accuracy</th>\n",
       "      <td>0.302207</td>\n",
       "      <td>0.787493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_precision</th>\n",
       "      <td>0.229205</td>\n",
       "      <td>0.788823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_recall</th>\n",
       "      <td>0.334466</td>\n",
       "      <td>0.792930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_f1</th>\n",
       "      <td>0.214603</td>\n",
       "      <td>0.790693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_runtime</th>\n",
       "      <td>162.845200</td>\n",
       "      <td>161.254400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <td>21.702000</td>\n",
       "      <td>21.916000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <td>21.702000</td>\n",
       "      <td>21.916000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Base Model  Fine-tuned Model\n",
       "eval_loss                      1.442186          0.935992\n",
       "eval_model_preparation_time    0.001900          0.003600\n",
       "eval_accuracy                  0.302207          0.787493\n",
       "eval_precision                 0.229205          0.788823\n",
       "eval_recall                    0.334466          0.792930\n",
       "eval_f1                        0.214603          0.790693\n",
       "eval_runtime                 162.845200        161.254400\n",
       "eval_samples_per_second       21.702000         21.916000\n",
       "eval_steps_per_second         21.702000         21.916000"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame([base_eval_results, eval_results], index=['Base Model', 'Fine-tuned Model'])\n",
    "\n",
    "results.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the evaluation we can see that the base model has the `accuracy of 30%` which is a lot less than the `79%` accuracy we got from the fine tune model. \n",
    "\n",
    "This is great. \n",
    "\n",
    "Our fine tuned model is wayyyy better than the base model without fine tune.\n",
    "\n",
    "We deserve more dance.\n",
    "\n",
    "![](https://media1.tenor.com/m/Ffl1k0f2bgIAAAAC/dance-moves.gif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
