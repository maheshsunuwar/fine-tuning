{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert'>\n",
    "\n",
    "### Fine Tuning LLM - BERT\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class='alert alert-success'>\n",
    "Lets Start.\n",
    "\n",
    "We will follow these steps:\n",
    "1. Choose a pre-trained model and a dataset\n",
    "2. Load the data\n",
    "3. Tokenizer\n",
    "4. Initialize our base model\n",
    "5. Evaluate the method\n",
    "6. Fine tune using the Trainer method\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert'>\n",
    "\n",
    "#### 1. Choose a pre-trained model and a dataset\n",
    "\n",
    "</div>\n",
    "\n",
    "Lets use *`BERT`* model and a *`twitter dataset`*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert'>\n",
    "\n",
    "#### 2. Load the dataset\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'text', 'label', 'label_text'],\n",
       "        num_rows: 27481\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'text', 'label', 'label_text'],\n",
       "        num_rows: 3534\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "twitter_dataset = load_dataset(\"mteb/tweet_sentiment_extraction\")\n",
    "twitter_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!!! The dataset is loaded now.\n",
    "\n",
    "As we can see there are two keys in the loaded dataset dictionary-`train` and `test`.\n",
    "\n",
    "Lets check how our data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               text  label  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going      1   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!      0   \n",
       "2  088c60f138                          my boss is bullying me...      0   \n",
       "3  9642c003ef                     what interview! leave me alone      0   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...      0   \n",
       "\n",
       "  label_text  \n",
       "0    neutral  \n",
       "1   negative  \n",
       "2   negative  \n",
       "3   negative  \n",
       "4   negative  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_dataset_df = pd.DataFrame(twitter_dataset['train'])\n",
    "\n",
    "train_dataset_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how many training data we have and how many label classes we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have total of 27481 training observations.\n",
      "We have 3 label classes -> ['neutral' 'negative' 'positive'] \n"
     ]
    }
   ],
   "source": [
    "print(f'We have total of {len(train_dataset_df)} training observations.')\n",
    "\n",
    "print(f'We have {len(train_dataset_df['label_text'].unique())} label classes -> {train_dataset_df['label_text'].unique()} ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. Let's quickly check if our data is imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_text\n",
       "neutral     40.457043\n",
       "positive    31.228849\n",
       "negative    28.314108\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if the labels have balanced data\n",
    "\n",
    "# counting the value and converting it to percentage\n",
    "label_percentage = train_dataset_df['label_text'].value_counts() / len(train_dataset_df) * 100\n",
    "label_percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good. Our data is not highly imbalanced. A little but not as bad.\n",
    "Let's visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 3 artists>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.barh(['neutral', 'negative', 'positive'], [label_percentage['neutral'], label_percentage['negative'], label_percentage['positive']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert'>\n",
    "\n",
    "#### 3. Base Evaluation\n",
    "</div>\n",
    "\n",
    "We can see from the label percentage that neutral has 40.46% of the data.\n",
    "\n",
    "So, if we do not train our model and just randomly predicted `neutral`, we will be correct `40.46%` of the time.\n",
    "\n",
    "So 40.46 is our base. \n",
    "\n",
    "The model we want to build should predict the classes better than this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.45704304792402\n"
     ]
    }
   ],
   "source": [
    "base_prediction_percentage = label_percentage.sort_values(ascending=False).iloc[0]\n",
    "print(float(base_prediction_percentage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert'>\n",
    "\n",
    "#### 4. Tokenizer\n",
    "</div>\n",
    "\n",
    "In order to pass the data to the pre-trained model, we need to tokenize it.\n",
    "\n",
    "Since we chose `BERT` as the model we want to fine tune, we should choose the tokenizer for BERT as well.\n",
    "\n",
    "We can do this by loading `google-bert/bert-base-cased`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='google-bert/bert-base-cased', vocab_size=28996, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('google-bert/bert-base-cased')\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As LLMs work with tokens, we need to tokenize our entire dataset using the tokenizer.\n",
    "\n",
    "We can use map method to apply the preprocessing function over the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'text', 'label', 'label_text', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 27481\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'text', 'label', 'label_text', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 3534\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_funtion(obervation):\n",
    "    # we want to tokenize 'text' column from our data\n",
    "    return tokenizer(obervation['text'], padding='max_length', truncation=True)\n",
    "\n",
    "tokenized_dataset = twitter_dataset.map(tokenize_funtion, batched=True)\n",
    "\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert'>\n",
    "\n",
    "#### 5. Initialize our pre-trained model\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "bert_model = BertForSequenceClassification.from_pretrained('google-bert/bert-base-uncased', num_labels=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=====================================================================================\n",
       "Layer (type:depth-idx)                                       Param #\n",
       "=====================================================================================\n",
       "BertForSequenceClassification                                --\n",
       "├─BertModel: 1-1                                             --\n",
       "│    └─BertEmbeddings: 2-1                                   --\n",
       "│    │    └─Embedding: 3-1                                   23,440,896\n",
       "│    │    └─Embedding: 3-2                                   393,216\n",
       "│    │    └─Embedding: 3-3                                   1,536\n",
       "│    │    └─LayerNorm: 3-4                                   1,536\n",
       "│    │    └─Dropout: 3-5                                     --\n",
       "│    └─BertEncoder: 2-2                                      --\n",
       "│    │    └─ModuleList: 3-6                                  85,054,464\n",
       "│    └─BertPooler: 2-3                                       --\n",
       "│    │    └─Linear: 3-7                                      590,592\n",
       "│    │    └─Tanh: 3-8                                        --\n",
       "├─Dropout: 1-2                                               --\n",
       "├─Linear: 1-3                                                2,307\n",
       "=====================================================================================\n",
       "Total params: 109,484,547\n",
       "Trainable params: 109,484,547\n",
       "Non-trainable params: 0\n",
       "====================================================================================="
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the summary of the model\n",
    "from torchinfo import summary\n",
    "\n",
    "summary(bert_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we have 109 million parameters.\n",
    "\n",
    "That means, when we fine-tune our model, it will tune those 109 million parameters.\n",
    "\n",
    "We can decrease the number of trainable parameters using different techniques (for ex. LoRA), which will drastically decrease the number of trainable parameter with no loss in performance. \n",
    "\n",
    "We will do it later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert'>\n",
    "\n",
    "#### 6. Initilaize the Evaluation and evaluate our pre-trained model\n",
    "</div>\n",
    "\n",
    "\n",
    "Default trainer doesn't give us information about accuracy, precision, recall, f1.\n",
    "\n",
    "We have to write a custom function that handles this.\n",
    "\n",
    "Lets do that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "def custom_metrics(predictions):\n",
    "    pred, labels = predictions\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    precision = precision_score(y_true=labels, y_pred=pred, average='macro')\n",
    "    recall = recall_score(y_true=labels, y_pred=pred, average='macro')\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred, average='macro')\n",
    "    # average = macro, we should do this for multiclass classfication\n",
    "    # we can choose from micro, macro, and weighted options\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(42)\n",
    "#configure training arguments for the evaluation\n",
    "# bert_model.eval()\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    per_device_eval_batch_size=1,\n",
    "    prediction_loss_only=False,\n",
    "    seed=42,\n",
    "    data_seed=42\n",
    ")\n",
    "\n",
    "pre_trained_evaluator =  Trainer(\n",
    "    model=bert_model,\n",
    "    args=training_arguments,\n",
    "    compute_metrics=custom_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3534' max='3534' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3534/3534 01:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pre_trained_eval_results = pre_trained_evaluator.evaluate(tokenized_dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bert Pretrained Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eval_loss</th>\n",
       "      <td>1.106310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_model_preparation_time</th>\n",
       "      <td>0.004100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_accuracy</th>\n",
       "      <td>0.310979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_precision</th>\n",
       "      <td>0.214811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_recall</th>\n",
       "      <td>0.331917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_f1</th>\n",
       "      <td>0.159338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_runtime</th>\n",
       "      <td>69.524600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <td>50.831000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <td>50.831000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Bert Pretrained Result\n",
       "eval_loss                                  1.106310\n",
       "eval_model_preparation_time                0.004100\n",
       "eval_accuracy                              0.310979\n",
       "eval_precision                             0.214811\n",
       "eval_recall                                0.331917\n",
       "eval_f1                                    0.159338\n",
       "eval_runtime                              69.524600\n",
       "eval_samples_per_second                   50.831000\n",
       "eval_steps_per_second                     50.831000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([pre_trained_eval_results], index=['Bert Pretrained Result']).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well well well!!!\n",
    "\n",
    "The eval accuracy of pre-trained BERT is 30-40.46% (depending on different run), which is similar to  as just predicting `neutral` or other classes, as we saw before. \n",
    "\n",
    "So our pretrained BERT is just randomly guessing the output class. \n",
    "\n",
    "Now Lets start our fine-tuning and see if we can improve it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert'>\n",
    "\n",
    "#### 7. Fine-tune the model\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10305' max='10305' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10305/10305 1:25:52, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.099700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.090300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.094900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.093200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.093500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.096800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.088100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.086500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.095600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>1.089300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.085600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>1.088000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>1.088500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>1.091600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>1.087200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>1.087700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>1.086900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>1.086000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.087400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10305, training_loss=1.0902164227866478, metrics={'train_runtime': 5153.1061, 'train_samples_per_second': 15.999, 'train_steps_per_second': 2.0, 'total_flos': 2.168738656964813e+16, 'train_loss': 1.0902164227866478, 'epoch': 2.999345025835092})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42) # seed for reproducibility\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir='test_trainer',\n",
    "    per_device_eval_batch_size=1,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    prediction_loss_only=False,\n",
    "    seed=42,\n",
    "    data_seed=42\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "   model=bert_model,\n",
    "   args=training_arguments,\n",
    "   train_dataset=tokenized_dataset['train'],\n",
    "   eval_dataset=tokenized_dataset['test'],\n",
    "   compute_metrics=custom_metrics,\n",
    ")\n",
    "\n",
    "#start the training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets check the performance of the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=====================================================================================\n",
       "Layer (type:depth-idx)                                       Param #\n",
       "=====================================================================================\n",
       "BertForSequenceClassification                                --\n",
       "├─BertModel: 1-1                                             --\n",
       "│    └─BertEmbeddings: 2-1                                   --\n",
       "│    │    └─Embedding: 3-1                                   23,440,896\n",
       "│    │    └─Embedding: 3-2                                   393,216\n",
       "│    │    └─Embedding: 3-3                                   1,536\n",
       "│    │    └─LayerNorm: 3-4                                   1,536\n",
       "│    │    └─Dropout: 3-5                                     --\n",
       "│    └─BertEncoder: 2-2                                      --\n",
       "│    │    └─ModuleList: 3-6                                  85,054,464\n",
       "│    └─BertPooler: 2-3                                       --\n",
       "│    │    └─Linear: 3-7                                      590,592\n",
       "│    │    └─Tanh: 3-8                                        --\n",
       "├─Dropout: 1-2                                               --\n",
       "├─Linear: 1-3                                                2,307\n",
       "=====================================================================================\n",
       "Total params: 109,484,547\n",
       "Trainable params: 109,484,547\n",
       "Non-trainable params: 0\n",
       "====================================================================================="
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "# load the model\n",
    "trained_model= BertForSequenceClassification.from_pretrained('test_trainer/checkpoint-2577', use_safetensors=True)\n",
    "\n",
    "# print the summary of the model\n",
    "summary(trained_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "its the same 109 million parameter model, but it is fine tuned in twitter dataset now.\n",
    "\n",
    "Lets evaluate the trained model now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "# configure the training arguments\n",
    "training_arguments = TrainingArguments(\n",
    "    per_device_eval_batch_size=1,\n",
    "    prediction_loss_only=False,\n",
    "    seed=42,\n",
    "    data_seed=42\n",
    ")\n",
    "\n",
    "# initialize he evaluator\n",
    "evaluator = Trainer(\n",
    "    model=trained_model,\n",
    "    args=training_arguments,\n",
    "    compute_metrics=custom_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3534' max='3534' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3534/3534 01:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# final evaluation result in test dataset\n",
    "eval_results = evaluator.evaluate(tokenized_dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bert fine-tuned result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eval_loss</th>\n",
       "      <td>0.733612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_model_preparation_time</th>\n",
       "      <td>0.003000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_accuracy</th>\n",
       "      <td>0.710526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_precision</th>\n",
       "      <td>0.717410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_recall</th>\n",
       "      <td>0.710982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_f1</th>\n",
       "      <td>0.713848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_runtime</th>\n",
       "      <td>67.592400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <td>52.284000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <td>52.284000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Bert fine-tuned result\n",
       "eval_loss                                  0.733612\n",
       "eval_model_preparation_time                0.003000\n",
       "eval_accuracy                              0.710526\n",
       "eval_precision                             0.717410\n",
       "eval_recall                                0.710982\n",
       "eval_f1                                    0.713848\n",
       "eval_runtime                              67.592400\n",
       "eval_samples_per_second                   52.284000\n",
       "eval_steps_per_second                     52.284000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([eval_results], index = ['Bert fine-tuned result']).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pretrained Model</th>\n",
       "      <th>Fine-tuned Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eval_loss</th>\n",
       "      <td>1.106310</td>\n",
       "      <td>0.733612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_model_preparation_time</th>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.003000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_accuracy</th>\n",
       "      <td>0.310979</td>\n",
       "      <td>0.710526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_precision</th>\n",
       "      <td>0.214811</td>\n",
       "      <td>0.717410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_recall</th>\n",
       "      <td>0.331917</td>\n",
       "      <td>0.710982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_f1</th>\n",
       "      <td>0.159338</td>\n",
       "      <td>0.713848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_runtime</th>\n",
       "      <td>69.524600</td>\n",
       "      <td>67.592400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <td>50.831000</td>\n",
       "      <td>52.284000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <td>50.831000</td>\n",
       "      <td>52.284000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Pretrained Model  Fine-tuned Model\n",
       "eval_loss                            1.106310          0.733612\n",
       "eval_model_preparation_time          0.004100          0.003000\n",
       "eval_accuracy                        0.310979          0.710526\n",
       "eval_precision                       0.214811          0.717410\n",
       "eval_recall                          0.331917          0.710982\n",
       "eval_f1                              0.159338          0.713848\n",
       "eval_runtime                        69.524600         67.592400\n",
       "eval_samples_per_second             50.831000         52.284000\n",
       "eval_steps_per_second               50.831000         52.284000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame([pre_trained_eval_results, eval_results], index=['Pretrained Model', 'Fine-tuned Model'])\n",
    "\n",
    "results.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good. We looks like our fine tuned model is twice as better as the pretrained BERT model.\n",
    "\n",
    "It bumped from 30% -> 71%.\n",
    "\n",
    "It is good but not as good. We need to make it even better. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert'>\n",
    "\n",
    "#### 8. Making our model even better\n",
    "\n",
    "</div>\n",
    "\n",
    "Now, what can do to make our model even better?\n",
    "\n",
    "Lets work on that now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
